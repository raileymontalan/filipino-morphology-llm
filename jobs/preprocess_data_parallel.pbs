#!/bin/bash

#PBS -N preprocess_parallel
#PBS -J 1-1
#PBS -l select=1:ncpus=32:mem=256GB
#PBS -l walltime=08:00:00
#PBS -q AISG_debug
#PBS -j oe
#PBS -o /scratch_aisg/SPEC-SF-AISG/railey/logs/

# ============================================================================
# Parallel Data Preprocessing with Job Arrays
# ============================================================================
#
# This script preprocesses multiple JSONL chunks in parallel using a PBS array job.
# Much faster than processing a single large file!
#
# Setup:
#   1. Split your large JSONL first:
#      python scripts/split_jsonl.py --input data.jsonl --output-dir data/chunks --num-chunks 20
#
#   2. Submit this array job:
#      qsub -J 1-20 jobs/preprocess_data_parallel.pbs
#      (where 20 = number of chunks)
#
# Each array task will process one chunk in parallel!
# ============================================================================

set -euo pipefail

# ============================================================================
# Setup Environment
# ============================================================================

export JOB_WORK_DIR=${PBS_O_WORKDIR}
export JOB_ID=${PBS_JOBID}
export JOB_NAME=${PBS_JOBNAME}
export ARRAY_INDEX=${PBS_ARRAY_INDEX:-1}

cd ${JOB_WORK_DIR}

# Load environment variables
if [ -f "${JOB_WORK_DIR}/.env" ]; then
    set +u  # Temporarily allow undefined variables
    source "${JOB_WORK_DIR}/.env"
    set -u
else
    echo "Error: .env file not found"
    exit 1
fi

# Export Enroot paths (critical for container to be found!)
export ENROOT_PATH=${ENROOT_PATH}
export ENROOT_CACHE_PATH=${ENROOT_CACHE_PATH}
export ENROOT_TEMP_PATH=${ENROOT_TEMP_PATH}
export ENROOT_DATA_PATH=${ENROOT_DATA_PATH}
export ENROOT_RUNTIME_PATH=${ENROOT_RUNTIME_PATH}

# ============================================================================
# Container Configuration
# ============================================================================

export CONTAINER_NAME="nemo_framework"

if ! enroot list | grep -q "^${CONTAINER_NAME}$"; then
    echo "Error: Container ${CONTAINER_NAME} not found"
    exit 1
fi

# ============================================================================
# Configuration
# ============================================================================

# Chunk directory (on host and in container)
export HOST_CHUNK_DIR="${JOB_WORK_DIR}/data/chunks"
export CONTAINER_CHUNK_DIR="/workspace/data/chunks"
export CONTAINER_OUTPUT_DIR="/workspace/data/processed"
export CHUNK_FILE_HOST=$(printf "${HOST_CHUNK_DIR}/chunk_%04d.jsonl" ${ARRAY_INDEX})
export CHUNK_FILE_CONTAINER=$(printf "${CONTAINER_CHUNK_DIR}/chunk_%04d.jsonl" ${ARRAY_INDEX})
export OUTPUT_PREFIX_CONTAINER=$(printf "${CONTAINER_OUTPUT_DIR}/chunk_%04d" ${ARRAY_INDEX})

export TOKENIZER="${TOKENIZER:-google/gemma-3-1b-pt}"
export WORKERS="${WORKERS:-64}"  # Use all CPUs!
export JSON_KEY="${JSON_KEY:-text}"

export LOG_DIR="/scratch_aisg/SPEC-SF-AISG/railey/logs/preprocessing/${PBS_JOBID%%\[*\]}/chunk_${ARRAY_INDEX}"
mkdir -p ${LOG_DIR}

# ============================================================================
# Print Configuration
# ============================================================================

echo "============================================================================"
echo "Parallel Preprocessing - Chunk ${ARRAY_INDEX}"
echo "============================================================================"
echo "Job ID: ${PBS_JOBID}"
echo "Array Index: ${ARRAY_INDEX}"
echo ""
echo "Input (host): ${CHUNK_FILE_HOST}"
echo "Input (container): ${CHUNK_FILE_CONTAINER}"
echo "Output: ${OUTPUT_PREFIX_CONTAINER}.{bin,idx}"
echo "Tokenizer: ${TOKENIZER}"
echo "Workers: ${WORKERS}"
echo "============================================================================"
echo ""

# ============================================================================
# Verify Input Exists (check on host filesystem)
# ============================================================================

if [ ! -f "${CHUNK_FILE_HOST}" ]; then
    echo "Error: Chunk file not found on host: ${CHUNK_FILE_HOST}"
    echo ""
    echo "Did you split the data first?"
    echo "  python scripts/split_jsonl.py --input data.jsonl --output-dir data/chunks --num-chunks N"
    echo ""
    echo "Chunks should be at: ${HOST_CHUNK_DIR}/"
    ls -lh "${HOST_CHUNK_DIR}/" 2>/dev/null || echo "Directory doesn't exist!"
    exit 1
fi

echo "✓ Chunk file found: ${CHUNK_FILE_HOST} ($(du -h ${CHUNK_FILE_HOST} | cut -f1))"
echo ""

# ============================================================================
# Build Enroot Command
# ============================================================================

ENROOT_MOUNTS="--mount ${JOB_WORK_DIR}:/workspace"

if [ -n "${BIND_MOUNTS:-}" ]; then
    IFS=',' read -ra MOUNTS <<< "$BIND_MOUNTS"
    for mount in "${MOUNTS[@]}"; do
        ENROOT_MOUNTS="${ENROOT_MOUNTS} --mount ${mount}"
    done
fi

ENROOT_ENV="-e HF_HOME=${HF_HOME} \
    -e HF_TOKEN=${HF_TOKEN}"

# ============================================================================
# Run Preprocessing
# ============================================================================

echo "Processing chunk ${ARRAY_INDEX}..."
echo ""

PYTHON_CMD="python /workspace/training/nemo/data/preprocess_data.py \
    --input ${CHUNK_FILE_CONTAINER} \
    --output-prefix ${OUTPUT_PREFIX_CONTAINER} \
    --tokenizer-model ${TOKENIZER} \
    --workers ${WORKERS} \
    --text-key ${JSON_KEY}"

enroot start --rw \
    ${ENROOT_ENV} \
    ${ENROOT_MOUNTS} \
    ${CONTAINER_NAME} \
    bash -c "${PYTHON_CMD}" 2>&1 | tee ${LOG_DIR}/preprocessing.log

EXIT_CODE=$?

if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "============================================================================"
    echo "✓ Chunk ${ARRAY_INDEX} Complete"
    echo "============================================================================"
    echo "Output files:"
    echo "  ${OUTPUT_PREFIX_CONTAINER}.bin"
    echo "  ${OUTPUT_PREFIX_CONTAINER}.idx"
    echo ""
    echo "Log: ${LOG_DIR}/preprocessing.log"
    echo "============================================================================"
else
    echo ""
    echo "============================================================================"
    echo "✗ Chunk ${ARRAY_INDEX} Failed (exit code: ${EXIT_CODE})"
    echo "============================================================================"
    echo "Check log: ${LOG_DIR}/preprocessing.log"
    echo "============================================================================"
    exit $EXIT_CODE
fi
